{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-10 22:10:14.639406 explore_iris_7: Loading data\n",
      "2019-04-10 22:10:14.866799 explore_iris_7: Splitting data into training and test sets\n",
      "2019-04-10 22:10:14.868794 explore_iris_7: Evaluate model Logistic Regression\n",
      "2019-04-10 22:10:15.456238 explore_iris_7: Evaluate model KNN Neighbors\n",
      "2019-04-10 22:10:15.476184 explore_iris_7: Evaluate model Support Vector\n",
      "2019-04-10 22:10:16.224168 explore_iris_7: Evaluate model DecisionTree\n",
      "2019-04-10 22:10:16.352826 explore_iris_7: Evaluate model Random Forest\n",
      " Logistic Regression: \t\t0.535000\t(0.041382)\n",
      "       KNN Neighbors: \t\t0.352500\t(0.042866)\n",
      "      Support Vector: \t\t0.081250\t(0.025769)\n",
      "        DecisionTree: \t\t0.430000\t(0.040000)\n",
      "       Random Forest: \t\t0.535000\t(0.049937)\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.656015 Begin training:  Logistic Regression\n",
      "2019-04-10 22:10:16.720856 End training:  Logistic Regression\n",
      "2019-04-10 22:10:16.720856 Begin prediction:  Logistic Regression\n",
      "2019-04-10 22:10:16.721841 End prediction:  Logistic Regression\n",
      "\n",
      "Logistic Regression: accuracy_score=0.53\n",
      "[[ 9  0  1  0  0  3  2  0  1  2]\n",
      " [ 0 14  0  0  0  0  0  0  2  1]\n",
      " [ 3  0 11  0  1  0  0  0  1  1]\n",
      " [ 0  0  1 13  3  0  1  1  0  2]\n",
      " [ 0  1  4  3  4  2  1  2  3  1]\n",
      " [ 1  3  1  1  0 10  0  1  1  0]\n",
      " [ 1  0  0  0  1  0 14  0  0  0]\n",
      " [ 0  0  1  1  0  0  0 24  1  0]\n",
      " [ 0  0  1  3  8  1  0  0  5  0]\n",
      " [ 8  0  3  8  0  2  3  1  1  1]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.41      0.50      0.45        18\n",
      "  classical       0.78      0.82      0.80        17\n",
      "    country       0.48      0.65      0.55        17\n",
      "      disco       0.45      0.62      0.52        21\n",
      "     hiphop       0.24      0.19      0.21        21\n",
      "       jazz       0.56      0.56      0.56        18\n",
      "      metal       0.67      0.88      0.76        16\n",
      "        pop       0.83      0.89      0.86        27\n",
      "     reggae       0.33      0.28      0.30        18\n",
      "       rock       0.12      0.04      0.06        27\n",
      "\n",
      "avg / total       0.48      0.53      0.49       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.725826 Begin training:  KNeighbors Classifier\n",
      "2019-04-10 22:10:16.727821 End training:  KNeighbors Classifier\n",
      "2019-04-10 22:10:16.727821 Begin prediction:  KNeighbors Classifier\n",
      "2019-04-10 22:10:16.730814 End prediction:  KNeighbors Classifier\n",
      "\n",
      "KNeighbors Classifier: accuracy_score=0.38\n",
      "[[10  1  2  0  0  1  1  0  2  1]\n",
      " [ 2 13  1  0  0  1  0  0  0  0]\n",
      " [ 4  0  6  0  0  0  0  1  6  0]\n",
      " [ 3  0  1  5  2  0  4  3  1  2]\n",
      " [ 4  0  4  3  6  1  1  1  0  1]\n",
      " [ 3  4  1  0  1  5  0  1  3  0]\n",
      " [ 1  0  0  1  1  0 12  0  0  1]\n",
      " [ 0  0  1  5  5  2  0 12  2  0]\n",
      " [ 0  0  3  4  2  2  0  2  5  0]\n",
      " [ 4  0  8  1  2  1  7  0  3  1]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.32      0.56      0.41        18\n",
      "  classical       0.72      0.76      0.74        17\n",
      "    country       0.22      0.35      0.27        17\n",
      "      disco       0.26      0.24      0.25        21\n",
      "     hiphop       0.32      0.29      0.30        21\n",
      "       jazz       0.38      0.28      0.32        18\n",
      "      metal       0.48      0.75      0.59        16\n",
      "        pop       0.60      0.44      0.51        27\n",
      "     reggae       0.23      0.28      0.25        18\n",
      "       rock       0.17      0.04      0.06        27\n",
      "\n",
      "avg / total       0.37      0.38      0.36       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.732807 Begin training:  Support Vector\n",
      "2019-04-10 22:10:16.849496 End training:  Support Vector\n",
      "2019-04-10 22:10:16.850493 Begin prediction:  Support Vector\n",
      "2019-04-10 22:10:16.865453 End prediction:  Support Vector\n",
      "\n",
      "Support Vector: accuracy_score=0.12\n",
      "[[ 0  0 18  0  0  0  0  0  0  0]\n",
      " [ 0  1 16  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  1  0  0  0  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0  2  0  0  0]\n",
      " [ 0  0 26  0  0  0  0  1  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  1  0]\n",
      " [ 0  0 26  0  0  0  1  0  0  0]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.00      0.00      0.00        18\n",
      "  classical       1.00      0.06      0.11        17\n",
      "    country       0.09      1.00      0.16        17\n",
      "      disco       0.00      0.00      0.00        21\n",
      "     hiphop       1.00      0.05      0.09        21\n",
      "       jazz       0.00      0.00      0.00        18\n",
      "      metal       0.67      0.12      0.21        16\n",
      "        pop       1.00      0.04      0.07        27\n",
      "     reggae       1.00      0.06      0.11        18\n",
      "       rock       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.48      0.12      0.07       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.870442 Begin training:  Decision Tree Classifier\n",
      "2019-04-10 22:10:16.891384 End training:  Decision Tree Classifier\n",
      "2019-04-10 22:10:16.891384 Begin prediction:  Decision Tree Classifier\n",
      "2019-04-10 22:10:16.891384 End prediction:  Decision Tree Classifier\n",
      "\n",
      "Decision Tree Classifier: accuracy_score=0.49\n",
      "[[ 8  1  4  0  1  2  1  0  0  1]\n",
      " [ 0 13  3  0  0  0  0  0  1  0]\n",
      " [ 4  0  9  0  1  0  0  1  1  1]\n",
      " [ 0  0  4  6  4  1  1  2  0  3]\n",
      " [ 2  0  0  4  7  1  0  1  6  0]\n",
      " [ 1  1  0  0  1  9  0  0  2  4]\n",
      " [ 2  0  0  1  1  0 12  0  0  0]\n",
      " [ 0  1  2  0  1  1  0 20  0  2]\n",
      " [ 0  1  2  2  0  1  0  2 10  0]\n",
      " [ 6  1  7  1  1  3  2  1  1  4]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.35      0.44      0.39        18\n",
      "  classical       0.72      0.76      0.74        17\n",
      "    country       0.29      0.53      0.38        17\n",
      "      disco       0.43      0.29      0.34        21\n",
      "     hiphop       0.41      0.33      0.37        21\n",
      "       jazz       0.50      0.50      0.50        18\n",
      "      metal       0.75      0.75      0.75        16\n",
      "        pop       0.74      0.74      0.74        27\n",
      "     reggae       0.48      0.56      0.51        18\n",
      "       rock       0.27      0.15      0.19        27\n",
      "\n",
      "avg / total       0.49      0.49      0.48       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.896372 Begin training:  Random Forest\n",
      "2019-04-10 22:10:16.929283 End training:  Random Forest\n",
      "2019-04-10 22:10:16.929283 Begin prediction:  Random Forest\n",
      "2019-04-10 22:10:16.931277 End prediction:  Random Forest\n",
      "\n",
      "Random Forest: accuracy_score=0.58\n",
      "[[14  0  0  0  0  3  1  0  0  0]\n",
      " [ 0 15  0  1  0  0  0  0  1  0]\n",
      " [ 5  0  9  0  2  0  0  0  0  1]\n",
      " [ 0  0  2  7  3  0  2  2  3  2]\n",
      " [ 1  0  1  3 11  0  1  2  1  1]\n",
      " [ 2  1  2  1  0 10  0  1  1  0]\n",
      " [ 1  0  0  0  2  0 13  0  0  0]\n",
      " [ 0  0  2  0  0  1  0 21  2  1]\n",
      " [ 1  0  4  2  3  0  0  0  8  0]\n",
      " [ 3  0  7  2  0  1  3  0  2  9]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.52      0.78      0.62        18\n",
      "  classical       0.94      0.88      0.91        17\n",
      "    country       0.33      0.53      0.41        17\n",
      "      disco       0.44      0.33      0.38        21\n",
      "     hiphop       0.52      0.52      0.52        21\n",
      "       jazz       0.67      0.56      0.61        18\n",
      "      metal       0.65      0.81      0.72        16\n",
      "        pop       0.81      0.78      0.79        27\n",
      "     reggae       0.44      0.44      0.44        18\n",
      "       rock       0.64      0.33      0.44        27\n",
      "\n",
      "avg / total       0.60      0.58      0.58       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.934269 Begin training:  My Random\n",
      "2019-04-10 22:10:16.934269 End training:  My Random\n",
      "2019-04-10 22:10:16.934269 Begin prediction:  My Random\n",
      "2019-04-10 22:10:16.934269 End prediction:  My Random\n",
      "\n",
      "My Random: accuracy_score=0.07\n",
      "[[1 1 3 3 3 0 1 2 4 0]\n",
      " [3 1 1 1 2 3 0 4 2 0]\n",
      " [2 3 2 1 1 3 0 2 2 1]\n",
      " [4 2 5 0 1 0 2 1 3 3]\n",
      " [1 3 3 3 2 2 1 2 1 3]\n",
      " [0 0 1 3 1 2 4 3 2 2]\n",
      " [2 3 2 1 0 2 1 4 0 1]\n",
      " [2 4 4 2 3 2 4 2 1 3]\n",
      " [2 1 2 3 0 3 2 1 1 3]\n",
      " [4 2 0 5 2 3 3 2 3 3]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.05      0.06      0.05        18\n",
      "  classical       0.05      0.06      0.05        17\n",
      "    country       0.09      0.12      0.10        17\n",
      "      disco       0.00      0.00      0.00        21\n",
      "     hiphop       0.13      0.10      0.11        21\n",
      "       jazz       0.10      0.11      0.11        18\n",
      "      metal       0.06      0.06      0.06        16\n",
      "        pop       0.09      0.07      0.08        27\n",
      "     reggae       0.05      0.06      0.05        18\n",
      "       rock       0.16      0.11      0.13        27\n",
      "\n",
      "avg / total       0.08      0.07      0.08       200\n",
      "\n",
      "\n",
      "2019-04-10 22:10:16.938261 Begin training:  My KNN\n",
      "2019-04-10 22:10:16.938261 End training:  My KNN\n",
      "2019-04-10 22:10:16.938261 Begin prediction:  My KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-10 22:10:18.625761 End prediction:  My KNN\n",
      "\n",
      "My KNN: accuracy_score=0.41\n",
      "[[ 8  1  1  1  0  1  1  0  2  3]\n",
      " [ 1 13  1  0  0  2  0  0  0  0]\n",
      " [ 5  0  4  1  0  1  0  1  4  1]\n",
      " [ 2  0  2  9  2  1  1  3  0  1]\n",
      " [ 2  1  2  1  2  4  1  2  3  3]\n",
      " [ 2  1  3  0  1  6  0  1  4  0]\n",
      " [ 0  0  0  3  0  0 10  0  0  3]\n",
      " [ 0  0  1  2  5  2  0 14  3  0]\n",
      " [ 0  0  3  1  2  0  0  1 10  1]\n",
      " [ 3  0  6  0  3  3  3  0  3  6]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      blues       0.35      0.44      0.39        18\n",
      "  classical       0.81      0.76      0.79        17\n",
      "    country       0.17      0.24      0.20        17\n",
      "      disco       0.50      0.43      0.46        21\n",
      "     hiphop       0.13      0.10      0.11        21\n",
      "       jazz       0.30      0.33      0.32        18\n",
      "      metal       0.62      0.62      0.62        16\n",
      "        pop       0.64      0.52      0.57        27\n",
      "     reggae       0.34      0.56      0.43        18\n",
      "       rock       0.33      0.22      0.27        27\n",
      "\n",
      "avg / total       0.42      0.41      0.41       200\n",
      "\n",
      "\n",
      "Algorithm\t\tAccuracy Score\n",
      " Logistic Regression\t\t0.53\n",
      "       KNN Neighbors\t\t0.38\n",
      "      Support Vector\t\t0.12\n",
      "        DecisionTree\t\t0.49\n",
      "       Random Forest\t\t0.58\n",
      "           My random\t\t0.12\n",
      "              My KNN\t\t0.41\n"
     ]
    }
   ],
   "source": [
    "# iris7_explore_7models.py\n",
    "\n",
    "# Load system libraries\n",
    "import sys\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Load ML libraries\n",
    "import pandas\n",
    "\n",
    "from numpy.random import shuffle\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SVMClassifier\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\t\n",
    "def _main():\n",
    "\tif (_showingHelp()):\n",
    "\t\t_showHelp()\n",
    "\t\texit(0)\n",
    "\t\t\n",
    "\tif (_showingVersions()):\n",
    "\t\t_showVersions()\n",
    "\t\t\n",
    "\t# load dataset\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"explore_iris_7: Loading data\");\n",
    "\turl = \"file:///C:/Users/zache/jupyterMemes/Decibel2/data_better.csv\"\n",
    "\t# url = \"file:///<file path here>/iris.csv\"\n",
    "\tnames = ['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'label'];\n",
    "\tdataset = pandas.read_csv(url, names=names)\n",
    "\n",
    "\tif (_showingSamples()):\n",
    "\t\t_sampleData(dataset)\n",
    "\t\t_visualizeData(dataset, pyplot, scatter_matrix)\n",
    "\n",
    "\t# split data into train/test datasets\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"explore_iris_7: Splitting data into training and test sets\");\n",
    "\tarray = dataset.values\n",
    "\tX = array[:,0:25]\n",
    "\tX = X.astype('double')\n",
    "\tY = array[:,25]\n",
    "\tY = Y.astype('str')\n",
    "\ttest_size = 0.20\n",
    "\tseed = 7\n",
    "\tX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\t# test options and perform evaluation metric\n",
    "\tseed = 7\n",
    "\tscoring = 'accuracy'\n",
    "\tmodels = []\n",
    "\tmodels.append(('Logistic Regression', LogisticRegression()))\n",
    "\tmodels.append(('KNN Neighbors', KNeighborsClassifier()))\n",
    "\tmodels.append(('Support Vector', SVMClassifier()))\n",
    "\tmodels.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('Random Forest', RandomForestClassifier()))\n",
    "\t\n",
    "\tif (not _showingSummaryOnly()):\n",
    "\t\t# evaluate models\n",
    "\t\tresults = []\n",
    "\t\tnames = []\n",
    "\t\tmsg = \"\"\n",
    "\t\tfor name, model in models:\n",
    "\t\t\tprint(datetime.datetime.now(), \"explore_iris_7: Evaluate model %s\" % name);\n",
    "\t\t\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\t\t\tcv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\t\t\tresults.append(cv_results)\n",
    "\t\t\tnames.append(name)\n",
    "\t\t\tmsg += \"%20s: \\t\\t%f\\t(%f)\" % (name, cv_results.mean(), cv_results.std()) + \"\\n\"\n",
    "\t\tprint(msg)\n",
    "\t\tprint();\n",
    "\t\t\n",
    "\tif ((_showingEval())):\n",
    "\t\t# compare algorithms\n",
    "\t\tfig = pyplot.figure()\n",
    "\t\tfig.suptitle('Compare algorithms')\n",
    "\t\tax = fig.add_subplot(111)\n",
    "\t\tpyplot.boxplot(results)\n",
    "\t\tax.set_xticklabels(names)\n",
    "\t\tpyplot.show()\n",
    "\n",
    "\t# make predictions on test dataset\n",
    "\tlor = LogisticRegression()\n",
    "\t_train(lor, \"Logistic Regression\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(lor, \"Logistic Regression\", X_train, Y_train, X_test, Y_test)\n",
    "\t\n",
    "\tknn = KNeighborsClassifier()\n",
    "\t_train(knn, \"KNeighbors Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(knn, \"KNeighbors Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tsvm = SVMClassifier()\n",
    "\t_train(svm, \"Support Vector\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(svm, \"Support Vector\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tdtc = DecisionTreeClassifier()\n",
    "\t_train(dtc, \"Decision Tree Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(dtc, \"Decision Tree Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\trfc = RandomForestClassifier()\n",
    "\t_train(rfc, \"Random Forest\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(rfc, \"Random Forest\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmyrnd = myRNDClassifier()\n",
    "\t_train(myrnd, \"My Random\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(myrnd, \"My Random\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmyknn = myKNNClassifier()\n",
    "\t_train(myknn, \"My KNN\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(myknn, \"My KNN\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmodels.clear()\n",
    "\tmodels.append(('Logistic Regression', lor))\n",
    "\tmodels.append(('KNN Neighbors', knn))\n",
    "\tmodels.append(('Support Vector', svm))\n",
    "\tmodels.append(('DecisionTree', dtc))\n",
    "\tmodels.append(('Random Forest', rfc))\n",
    "\tmodels.append(('My random', myrnd))\n",
    "\tmodels.append(('My KNN', myknn))\n",
    "\t\n",
    "\t_predictionAccuracySummary(models, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "#####################################################\n",
    "# My random classifier\n",
    "class myRNDClassifier:\n",
    "\tdef fit(self, X_train, y_train):\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\t\t\n",
    "\tdef predict(self, X_test):\n",
    "\t\tpredictions = []\n",
    "\t\tfor row in X_test:\n",
    "\t\t\tlabel = random.choice(self.y_train)\n",
    "\t\t\tpredictions.append(label)\n",
    "\t\t\t\n",
    "\t\treturn predictions\n",
    "\n",
    "#####################################################\n",
    "# My KNN K =1 classifier\n",
    "class myKNNClassifier:\n",
    "\tdef fit(self, X_train, y_train):\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\t\t\n",
    "\tdef predict(self, X_test):\n",
    "\t\tpredictions = []\n",
    "\t\tfor row in X_test:\n",
    "\t\t\tlabel = self.closest(row)\n",
    "\t\t\tpredictions.append(label)\n",
    "\t\treturn predictions\n",
    "\t\n",
    "\tdef closest(self, row):\n",
    "\t\tbest_distance = euc(row, self.X_train[0])\n",
    "\t\tbest_index = 0\n",
    "\t\tfor i in range(1, len(self.X_train)):\n",
    "\t\t\tdist = euc(row, self.X_train[i])\n",
    "\t\t\tif (dist < best_distance):\n",
    "\t\t\t\tbest_distance = dist\n",
    "\t\t\t\tbest_index = i\n",
    "\t\t\t\t\n",
    "\t\treturn(self.y_train[best_index])\n",
    "\n",
    "def euc(a,b):\n",
    "\treturn(distance.euclidean(a,b))\n",
    "\t\t\t\n",
    "#####################################################\n",
    "# training and prediction functions\n",
    "def _train(alg, algName, X_train, Y_train, X_test, Y_test):\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"Begin training: \", algName)\n",
    "\talg.fit(X_train, Y_train)\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"End training: \", algName)\n",
    "\n",
    "def _predict(alg, algName, X_train, Y_train, X_test, Y_test):\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"Begin prediction: \", algName)\n",
    "\tpredictions = alg.predict(X_test)\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"End prediction: \", algName)\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\tif (not _showingSummaryOnly()): print(\"%s: accuracy_score=%0.2f\" % (algName, accuracy_score(Y_test, predictions)))\n",
    "\tif (not _showingSummaryOnly()): print(confusion_matrix(Y_test, predictions))\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\tif (not _showingSummaryOnly()): print(classification_report(Y_test, predictions))\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\n",
    "def _predictionAccuracySummary(models, X_train, Y_train, X_test, Y_test):\n",
    "\tprint(\"Algorithm\\t\\tAccuracy Score\")\n",
    "\tfor name, model in models:\n",
    "\t\tpredictions = model.predict(X_test)\n",
    "\t\tprint(\"%20s\\t\\t%0.2f\" % (name, accuracy_score(Y_test, predictions)))\n",
    "\t\n",
    "#####################################################\n",
    "# data sampling and visualization functions\n",
    "def _sampleData(dataset):\n",
    "\t# show shape, first 10 records, description of frame and its distribution\n",
    "\tprint(dataset.shape)\n",
    "\tprint(dataset.head(20))\n",
    "\tprint(dataset.describe())\n",
    "\n",
    "\t# show class distribution and distribution by sepal-length\n",
    "\tprint(dataset.groupby('class').size())\n",
    "\tprint(dataset.groupby('sepal-length').size())\n",
    "\n",
    "def _visualizeData(dataset, pyplot, scatter_matrix):\n",
    "\t# visualize data and draw box and whisker plots\n",
    "\tdataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "\tpyplot.show()\n",
    "\n",
    "\t# show histograms and scatter plot matrix\n",
    "\tdataset.hist()\n",
    "\tpyplot.show()\n",
    "\tscatter_matrix(dataset)\n",
    "\tpyplot.show()\n",
    "\t\n",
    "#####################################################\n",
    "# helper functions\n",
    "def _parseArgumets(arg):\n",
    "\tfor i in range(1, len(sys.argv)):\n",
    "\t\tif (sys.argv[i] == arg):\n",
    "\t\t\treturn 1\n",
    "\n",
    "def _showingHelp():\n",
    "\treturn(_parseArgumets(\"--help\"))\n",
    "\n",
    "def _showingSummaryOnly():\n",
    "\treturn(_parseArgumets(\"--summaryonly\"))\n",
    "\n",
    "def _showingVersions():\n",
    "\treturn(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--version\"))\n",
    "\n",
    "def _showingSamples():\n",
    "    return(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--sample\"))\n",
    "\n",
    "def _showingEval():\n",
    "    return(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--eval\"))\n",
    "\n",
    "def _showHelp():\n",
    "\tprint(\"iris7_explore_7models: syntax iris7_explore_7models --version --sample --eval --summaryonly\")\n",
    "\tprint(\"--help: show this help message\");\n",
    "\tprint(\"--version: show version info for Python runtime and ML libraries\");\n",
    "\tprint(\"--sample: show sample data\");\n",
    "\tprint(\"--eval: show evaluation of algorithms\")\n",
    "\tprint(\"--summaryonly: show only a summary of algorithms and their accuracy scores\")\n",
    "\n",
    "def _showVersions():\n",
    "\t# check versions of Python runtime and ML libraries\n",
    "\timport sys\n",
    "\tprint('Python: {}'.format(sys.version))\n",
    "\n",
    "\timport scipy\n",
    "\tprint('scipy: {}'.format(scipy.__version__))\n",
    "\n",
    "\timport numpy\n",
    "\tprint('numpy: {}'.format(numpy.__version__))\n",
    "\n",
    "\timport matplotlib\n",
    "\tprint('matplotlib: {}'.format(matplotlib.__version__))\n",
    "\n",
    "\timport pandas\n",
    "\tprint('pandas: {}'.format(pandas.__version__))\n",
    "\n",
    "\timport sklearn\n",
    "\tprint('sklearn: {}'.format(sklearn.__version__))\n",
    "\t\n",
    "_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
