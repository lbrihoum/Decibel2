{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 14:36:50.349929 explore_iris_7: Loading data\n",
      "2019-04-16 14:36:50.367061 explore_iris_7: Splitting data into training and test sets\n",
      "2019-04-16 14:36:50.369888 explore_iris_7: Evaluate model Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 14:36:51.064366 explore_iris_7: Evaluate model KNN Neighbors\n",
      "2019-04-16 14:36:51.095061 explore_iris_7: Evaluate model Support Vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 14:36:51.486935 explore_iris_7: Evaluate model DecisionTree\n",
      "2019-04-16 14:36:51.646897 explore_iris_7: Evaluate model Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression: \t\t0.537500\t(0.041079)\n",
      "       KNN Neighbors: \t\t0.352500\t(0.042866)\n",
      "      Support Vector: \t\t0.081250\t(0.025769)\n",
      "        DecisionTree: \t\t0.438750\t(0.046587)\n",
      "       Random Forest: \t\t0.548750\t(0.056306)\n",
      "\n",
      "\n",
      "2019-04-16 14:36:51.923667 Begin training:  Logistic Regression\n",
      "2019-04-16 14:36:51.997363 End training:  Logistic Regression\n",
      "2019-04-16 14:36:51.997455 Begin prediction:  Logistic Regression\n",
      "2019-04-16 14:36:52.005710 End prediction:  Logistic Regression\n",
      "\n",
      "Logistic Regression: accuracy_score=0.52\n",
      "[[ 9  0  1  0  0  3  2  0  1  2]\n",
      " [ 0 14  0  0  0  0  0  0  2  1]\n",
      " [ 3  0 11  1  1  0  0  0  1  0]\n",
      " [ 0  0  1 13  2  0  1  1  1  2]\n",
      " [ 0  1  4  3  3  2  1  2  4  1]\n",
      " [ 1  3  1  1  0 10  0  1  1  0]\n",
      " [ 1  0  0  0  1  0 14  0  0  0]\n",
      " [ 0  0  1  1  0  0  0 24  1  0]\n",
      " [ 0  0  1  3  8  1  0  0  5  0]\n",
      " [ 8  0  3  8  0  2  3  1  1  1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.41      0.50      0.45        18\n",
      "   classical       0.78      0.82      0.80        17\n",
      "     country       0.48      0.65      0.55        17\n",
      "       disco       0.43      0.62      0.51        21\n",
      "      hiphop       0.20      0.14      0.17        21\n",
      "        jazz       0.56      0.56      0.56        18\n",
      "       metal       0.67      0.88      0.76        16\n",
      "         pop       0.83      0.89      0.86        27\n",
      "      reggae       0.29      0.28      0.29        18\n",
      "        rock       0.14      0.04      0.06        27\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       200\n",
      "   macro avg       0.48      0.54      0.50       200\n",
      "weighted avg       0.47      0.52      0.49       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.012688 Begin training:  KNeighbors Classifier\n",
      "2019-04-16 14:36:52.014205 End training:  KNeighbors Classifier\n",
      "2019-04-16 14:36:52.014363 Begin prediction:  KNeighbors Classifier\n",
      "2019-04-16 14:36:52.016192 End prediction:  KNeighbors Classifier\n",
      "\n",
      "KNeighbors Classifier: accuracy_score=0.38\n",
      "[[10  1  2  0  0  1  1  0  2  1]\n",
      " [ 2 13  1  0  0  1  0  0  0  0]\n",
      " [ 4  0  6  0  0  0  0  1  6  0]\n",
      " [ 3  0  1  5  2  0  4  3  1  2]\n",
      " [ 4  0  4  3  6  1  1  1  0  1]\n",
      " [ 3  4  1  0  1  5  0  1  3  0]\n",
      " [ 1  0  0  1  1  0 12  0  0  1]\n",
      " [ 0  0  1  5  5  2  0 12  2  0]\n",
      " [ 0  0  3  4  2  2  0  2  5  0]\n",
      " [ 4  0  8  1  2  1  7  0  3  1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.32      0.56      0.41        18\n",
      "   classical       0.72      0.76      0.74        17\n",
      "     country       0.22      0.35      0.27        17\n",
      "       disco       0.26      0.24      0.25        21\n",
      "      hiphop       0.32      0.29      0.30        21\n",
      "        jazz       0.38      0.28      0.32        18\n",
      "       metal       0.48      0.75      0.59        16\n",
      "         pop       0.60      0.44      0.51        27\n",
      "      reggae       0.23      0.28      0.25        18\n",
      "        rock       0.17      0.04      0.06        27\n",
      "\n",
      "   micro avg       0.38      0.38      0.38       200\n",
      "   macro avg       0.37      0.40      0.37       200\n",
      "weighted avg       0.37      0.38      0.36       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.022553 Begin training:  Support Vector\n",
      "2019-04-16 14:36:52.068936 End training:  Support Vector\n",
      "2019-04-16 14:36:52.069280 Begin prediction:  Support Vector\n",
      "2019-04-16 14:36:52.075876 End prediction:  Support Vector\n",
      "\n",
      "Support Vector: accuracy_score=0.12\n",
      "[[ 0  0 18  0  0  0  0  0  0  0]\n",
      " [ 0  1 16  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  1  0  0  0  0  0]\n",
      " [ 0  0 18  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0  2  0  0  0]\n",
      " [ 0  0 26  0  0  0  0  1  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  1  0]\n",
      " [ 0  0 26  0  0  0  1  0  0  0]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.00      0.00      0.00        18\n",
      "   classical       1.00      0.06      0.11        17\n",
      "     country       0.09      1.00      0.16        17\n",
      "       disco       0.00      0.00      0.00        21\n",
      "      hiphop       1.00      0.05      0.09        21\n",
      "        jazz       0.00      0.00      0.00        18\n",
      "       metal       0.67      0.12      0.21        16\n",
      "         pop       1.00      0.04      0.07        27\n",
      "      reggae       1.00      0.06      0.11        18\n",
      "        rock       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.12      0.12      0.12       200\n",
      "   macro avg       0.48      0.13      0.08       200\n",
      "weighted avg       0.48      0.12      0.07       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.086128 Begin training:  Decision Tree Classifier\n",
      "2019-04-16 14:36:52.107557 End training:  Decision Tree Classifier\n",
      "2019-04-16 14:36:52.107725 Begin prediction:  Decision Tree Classifier\n",
      "2019-04-16 14:36:52.108466 End prediction:  Decision Tree Classifier\n",
      "\n",
      "Decision Tree Classifier: accuracy_score=0.45\n",
      "[[ 8  1  3  0  1  2  2  0  0  1]\n",
      " [ 0 12  3  0  0  0  0  0  2  0]\n",
      " [ 4  0  7  1  2  1  0  0  0  2]\n",
      " [ 0  0  2  4  5  0  2  4  1  3]\n",
      " [ 1  0  1  3  7  1  0  0  7  1]\n",
      " [ 2  0  2  0  1  8  0  1  2  2]\n",
      " [ 2  0  0  1  1  0 12  0  0  0]\n",
      " [ 0  1  2  0  2  3  0 19  0  0]\n",
      " [ 0  1  1  2  1  1  0  2 10  0]\n",
      " [ 4  1  4  1  1  3  6  1  3  3]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.38      0.44      0.41        18\n",
      "   classical       0.75      0.71      0.73        17\n",
      "     country       0.28      0.41      0.33        17\n",
      "       disco       0.33      0.19      0.24        21\n",
      "      hiphop       0.33      0.33      0.33        21\n",
      "        jazz       0.42      0.44      0.43        18\n",
      "       metal       0.55      0.75      0.63        16\n",
      "         pop       0.70      0.70      0.70        27\n",
      "      reggae       0.40      0.56      0.47        18\n",
      "        rock       0.25      0.11      0.15        27\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       200\n",
      "   macro avg       0.44      0.47      0.44       200\n",
      "weighted avg       0.44      0.45      0.43       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.115409 Begin training:  Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-16 14:36:52.147141 End training:  Random Forest\n",
      "2019-04-16 14:36:52.147256 Begin prediction:  Random Forest\n",
      "2019-04-16 14:36:52.150850 End prediction:  Random Forest\n",
      "\n",
      "Random Forest: accuracy_score=0.54\n",
      "[[13  0  0  0  0  1  2  0  1  1]\n",
      " [ 0 14  0  0  0  1  0  0  2  0]\n",
      " [ 7  0  6  0  1  1  0  0  2  0]\n",
      " [ 1  0  0 10  3  0  1  1  1  4]\n",
      " [ 1  0  0  6  9  2  0  0  2  1]\n",
      " [ 3  3  1  1  0  8  0  1  1  0]\n",
      " [ 1  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  0  5  1  0  1  0 20  0  0]\n",
      " [ 0  0  4  2  3  1  0  0  8  0]\n",
      " [ 7  0  6  3  0  1  3  1  1  5]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.39      0.72      0.51        18\n",
      "   classical       0.82      0.82      0.82        17\n",
      "     country       0.27      0.35      0.31        17\n",
      "       disco       0.43      0.48      0.45        21\n",
      "      hiphop       0.56      0.43      0.49        21\n",
      "        jazz       0.50      0.44      0.47        18\n",
      "       metal       0.71      0.94      0.81        16\n",
      "         pop       0.87      0.74      0.80        27\n",
      "      reggae       0.44      0.44      0.44        18\n",
      "        rock       0.45      0.19      0.26        27\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       200\n",
      "   macro avg       0.55      0.56      0.54       200\n",
      "weighted avg       0.55      0.54      0.53       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.157666 Begin training:  My Random\n",
      "2019-04-16 14:36:52.157725 End training:  My Random\n",
      "2019-04-16 14:36:52.157772 Begin prediction:  My Random\n",
      "2019-04-16 14:36:52.158102 End prediction:  My Random\n",
      "\n",
      "My Random: accuracy_score=0.10\n",
      "[[0 1 4 3 1 1 2 1 5 0]\n",
      " [1 2 2 2 1 2 2 2 0 3]\n",
      " [0 0 2 4 1 1 3 3 2 1]\n",
      " [1 3 4 4 1 0 2 2 0 4]\n",
      " [4 1 1 1 4 0 2 1 3 4]\n",
      " [1 3 2 0 3 0 0 3 4 2]\n",
      " [1 2 1 2 1 1 3 0 4 1]\n",
      " [3 1 5 2 5 3 2 1 4 1]\n",
      " [2 0 3 3 1 2 2 0 4 1]\n",
      " [0 4 2 3 4 4 5 3 1 1]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.00      0.00      0.00        18\n",
      "   classical       0.12      0.12      0.12        17\n",
      "     country       0.08      0.12      0.09        17\n",
      "       disco       0.17      0.19      0.18        21\n",
      "      hiphop       0.18      0.19      0.19        21\n",
      "        jazz       0.00      0.00      0.00        18\n",
      "       metal       0.13      0.19      0.15        16\n",
      "         pop       0.06      0.04      0.05        27\n",
      "      reggae       0.15      0.22      0.18        18\n",
      "        rock       0.06      0.04      0.04        27\n",
      "\n",
      "   micro avg       0.10      0.10      0.10       200\n",
      "   macro avg       0.09      0.11      0.10       200\n",
      "weighted avg       0.09      0.10      0.10       200\n",
      "\n",
      "\n",
      "2019-04-16 14:36:52.167731 Begin training:  My KNN\n",
      "2019-04-16 14:36:52.167800 End training:  My KNN\n",
      "2019-04-16 14:36:52.167859 Begin prediction:  My KNN\n",
      "2019-04-16 14:36:54.244662 End prediction:  My KNN\n",
      "\n",
      "My KNN: accuracy_score=0.41\n",
      "[[ 8  1  1  1  0  1  1  0  2  3]\n",
      " [ 1 13  1  0  0  2  0  0  0  0]\n",
      " [ 5  0  4  1  0  1  0  1  4  1]\n",
      " [ 2  0  2  9  2  1  1  3  0  1]\n",
      " [ 2  1  2  1  2  4  1  2  3  3]\n",
      " [ 2  1  3  0  1  6  0  1  4  0]\n",
      " [ 0  0  0  3  0  0 10  0  0  3]\n",
      " [ 0  0  1  2  5  2  0 14  3  0]\n",
      " [ 0  0  3  1  2  0  0  1 10  1]\n",
      " [ 3  0  6  0  3  3  3  0  3  6]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.35      0.44      0.39        18\n",
      "   classical       0.81      0.76      0.79        17\n",
      "     country       0.17      0.24      0.20        17\n",
      "       disco       0.50      0.43      0.46        21\n",
      "      hiphop       0.13      0.10      0.11        21\n",
      "        jazz       0.30      0.33      0.32        18\n",
      "       metal       0.62      0.62      0.62        16\n",
      "         pop       0.64      0.52      0.57        27\n",
      "      reggae       0.34      0.56      0.43        18\n",
      "        rock       0.33      0.22      0.27        27\n",
      "\n",
      "   micro avg       0.41      0.41      0.41       200\n",
      "   macro avg       0.42      0.42      0.42       200\n",
      "weighted avg       0.42      0.41      0.41       200\n",
      "\n",
      "\n",
      "Algorithm\t\tAccuracy Score\n",
      " Logistic Regression\t\t0.52\n",
      "       KNN Neighbors\t\t0.38\n",
      "      Support Vector\t\t0.12\n",
      "        DecisionTree\t\t0.45\n",
      "       Random Forest\t\t0.54\n",
      "           My random\t\t0.17\n",
      "              My KNN\t\t0.41\n"
     ]
    }
   ],
   "source": [
    "# Load system libraries\n",
    "import sys\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Load ML libraries\n",
    "import pandas\n",
    "\n",
    "from numpy.random import shuffle\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SVMClassifier\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\t\n",
    "def _main():\n",
    "\tif (_showingHelp()):\n",
    "\t\t_showHelp()\n",
    "\t\texit(0)\n",
    "\t\t\n",
    "\tif (_showingVersions()):\n",
    "\t\t_showVersions()\n",
    "\t\t\n",
    "\t# load dataset\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"explore_iris_7: Loading data\");\n",
    "\turl = \"file:/Users/bloop/dev/Decibels2/data_better.csv\"\n",
    "\t# url = \"file:///<file path here>/iris.csv\"\n",
    "\tnames = ['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'label'];\n",
    "\tdataset = pandas.read_csv(url, names=names)\n",
    "\n",
    "\tif (_showingSamples()):\n",
    "\t\t_sampleData(dataset)\n",
    "\t\t_visualizeData(dataset, pyplot, scatter_matrix)\n",
    "\n",
    "\t# split data into train/test datasets\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"explore_iris_7: Splitting data into training and test sets\");\n",
    "\tarray = dataset.values\n",
    "\tX = array[:,0:25]\n",
    "\tX = X.astype('double')\n",
    "\tY = array[:,25]\n",
    "\tY = Y.astype('str')\n",
    "\ttest_size = 0.20\n",
    "\tseed = 7\n",
    "\tX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\t# test options and perform evaluation metric\n",
    "\tseed = 7\n",
    "\tscoring = 'accuracy'\n",
    "\tmodels = []\n",
    "\tmodels.append(('Logistic Regression', LogisticRegression()))\n",
    "\tmodels.append(('KNN Neighbors', KNeighborsClassifier()))\n",
    "\tmodels.append(('Support Vector', SVMClassifier()))\n",
    "\tmodels.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "\tmodels.append(('Random Forest', RandomForestClassifier()))\n",
    "\t\n",
    "\tif (not _showingSummaryOnly()):\n",
    "\t\t# evaluate models\n",
    "\t\tresults = []\n",
    "\t\tnames = []\n",
    "\t\tmsg = \"\"\n",
    "\t\tfor name, model in models:\n",
    "\t\t\tprint(datetime.datetime.now(), \"explore_iris_7: Evaluate model %s\" % name);\n",
    "\t\t\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\t\t\tcv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\t\t\tresults.append(cv_results)\n",
    "\t\t\tnames.append(name)\n",
    "\t\t\tmsg += \"%20s: \\t\\t%f\\t(%f)\" % (name, cv_results.mean(), cv_results.std()) + \"\\n\"\n",
    "\t\tprint(msg)\n",
    "\t\tprint();\n",
    "\t\t\n",
    "\tif ((_showingEval())):\n",
    "\t\t# compare algorithms\n",
    "\t\tfig = pyplot.figure()\n",
    "\t\tfig.suptitle('Compare algorithms')\n",
    "\t\tax = fig.add_subplot(111)\n",
    "\t\tpyplot.boxplot(results)\n",
    "\t\tax.set_xticklabels(names)\n",
    "\t\tpyplot.show()\n",
    "\n",
    "\t# make predictions on test dataset\n",
    "\tlor = LogisticRegression()\n",
    "\t_train(lor, \"Logistic Regression\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(lor, \"Logistic Regression\", X_train, Y_train, X_test, Y_test)\n",
    "\t\n",
    "\tknn = KNeighborsClassifier()\n",
    "\t_train(knn, \"KNeighbors Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(knn, \"KNeighbors Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tsvm = SVMClassifier()\n",
    "\t_train(svm, \"Support Vector\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(svm, \"Support Vector\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tdtc = DecisionTreeClassifier()\n",
    "\t_train(dtc, \"Decision Tree Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(dtc, \"Decision Tree Classifier\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\trfc = RandomForestClassifier()\n",
    "\t_train(rfc, \"Random Forest\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(rfc, \"Random Forest\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmyrnd = myRNDClassifier()\n",
    "\t_train(myrnd, \"My Random\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(myrnd, \"My Random\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmyknn = myKNNClassifier()\n",
    "\t_train(myknn, \"My KNN\", X_train, Y_train, X_test, Y_test)\n",
    "\t_predict(myknn, \"My KNN\", X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "\tmodels.clear()\n",
    "\tmodels.append(('Logistic Regression', lor))\n",
    "\tmodels.append(('KNN Neighbors', knn))\n",
    "\tmodels.append(('Support Vector', svm))\n",
    "\tmodels.append(('DecisionTree', dtc))\n",
    "\tmodels.append(('Random Forest', rfc))\n",
    "\tmodels.append(('My random', myrnd))\n",
    "\tmodels.append(('My KNN', myknn))\n",
    "\t\n",
    "\t_predictionAccuracySummary(models, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "#####################################################\n",
    "# My random classifier\n",
    "class myRNDClassifier:\n",
    "\tdef fit(self, X_train, y_train):\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\t\t\n",
    "\tdef predict(self, X_test):\n",
    "\t\tpredictions = []\n",
    "\t\tfor row in X_test:\n",
    "\t\t\tlabel = random.choice(self.y_train)\n",
    "\t\t\tpredictions.append(label)\n",
    "\t\t\t\n",
    "\t\treturn predictions\n",
    "\n",
    "#####################################################\n",
    "# My KNN K =1 classifier\n",
    "class myKNNClassifier:\n",
    "\tdef fit(self, X_train, y_train):\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\t\t\n",
    "\tdef predict(self, X_test):\n",
    "\t\tpredictions = []\n",
    "\t\tfor row in X_test:\n",
    "\t\t\tlabel = self.closest(row)\n",
    "\t\t\tpredictions.append(label)\n",
    "\t\treturn predictions\n",
    "\t\n",
    "\tdef closest(self, row):\n",
    "\t\tbest_distance = euc(row, self.X_train[0])\n",
    "\t\tbest_index = 0\n",
    "\t\tfor i in range(1, len(self.X_train)):\n",
    "\t\t\tdist = euc(row, self.X_train[i])\n",
    "\t\t\tif (dist < best_distance):\n",
    "\t\t\t\tbest_distance = dist\n",
    "\t\t\t\tbest_index = i\n",
    "\t\t\t\t\n",
    "\t\treturn(self.y_train[best_index])\n",
    "\n",
    "def euc(a,b):\n",
    "\treturn(distance.euclidean(a,b))\n",
    "\t\t\t\n",
    "#####################################################\n",
    "# training and prediction functions\n",
    "def _train(alg, algName, X_train, Y_train, X_test, Y_test):\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"Begin training: \", algName)\n",
    "\talg.fit(X_train, Y_train)\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"End training: \", algName)\n",
    "\n",
    "def _predict(alg, algName, X_train, Y_train, X_test, Y_test):\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"Begin prediction: \", algName)\n",
    "\tpredictions = alg.predict(X_test)\n",
    "\tif (not _showingSummaryOnly()): print(datetime.datetime.now(), \"End prediction: \", algName)\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\tif (not _showingSummaryOnly()): print(\"%s: accuracy_score=%0.2f\" % (algName, accuracy_score(Y_test, predictions)))\n",
    "\tif (not _showingSummaryOnly()): print(confusion_matrix(Y_test, predictions))\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\tif (not _showingSummaryOnly()): print(classification_report(Y_test, predictions))\n",
    "\tif (not _showingSummaryOnly()): print()\n",
    "\n",
    "def _predictionAccuracySummary(models, X_train, Y_train, X_test, Y_test):\n",
    "\tprint(\"Algorithm\\t\\tAccuracy Score\")\n",
    "\tfor name, model in models:\n",
    "\t\tpredictions = model.predict(X_test)\n",
    "\t\tprint(\"%20s\\t\\t%0.2f\" % (name, accuracy_score(Y_test, predictions)))\n",
    "\t\n",
    "#####################################################\n",
    "# data sampling and visualization functions\n",
    "def _sampleData(dataset):\n",
    "\t# show shape, first 10 records, description of frame and its distribution\n",
    "\tprint(dataset.shape)\n",
    "\tprint(dataset.head(20))\n",
    "\tprint(dataset.describe())\n",
    "\n",
    "\t# show class distribution and distribution by sepal-length\n",
    "\tprint(dataset.groupby('class').size())\n",
    "\tprint(dataset.groupby('sepal-length').size())\n",
    "\n",
    "def _visualizeData(dataset, pyplot, scatter_matrix):\n",
    "\t# visualize data and draw box and whisker plots\n",
    "\tdataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "\tpyplot.show()\n",
    "\n",
    "\t# show histograms and scatter plot matrix\n",
    "\tdataset.hist()\n",
    "\tpyplot.show()\n",
    "\tscatter_matrix(dataset)\n",
    "\tpyplot.show()\n",
    "\t\n",
    "#####################################################\n",
    "# helper functions\n",
    "def _parseArgumets(arg):\n",
    "\tfor i in range(1, len(sys.argv)):\n",
    "\t\tif (sys.argv[i] == arg):\n",
    "\t\t\treturn 1\n",
    "\n",
    "def _showingHelp():\n",
    "\treturn(_parseArgumets(\"--help\"))\n",
    "\n",
    "def _showingSummaryOnly():\n",
    "\treturn(_parseArgumets(\"--summaryonly\"))\n",
    "\n",
    "def _showingVersions():\n",
    "\treturn(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--version\"))\n",
    "\n",
    "def _showingSamples():\n",
    "    return(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--sample\"))\n",
    "\n",
    "def _showingEval():\n",
    "    return(not _parseArgumets(\"--summaryonly\") and _parseArgumets(\"--eval\"))\n",
    "\n",
    "def _showHelp():\n",
    "\tprint(\"iris7_explore_7models: syntax iris7_explore_7models --version --sample --eval --summaryonly\")\n",
    "\tprint(\"--help: show this help message\");\n",
    "\tprint(\"--version: show version info for Python runtime and ML libraries\");\n",
    "\tprint(\"--sample: show sample data\");\n",
    "\tprint(\"--eval: show evaluation of algorithms\")\n",
    "\tprint(\"--summaryonly: show only a summary of algorithms and their accuracy scores\")\n",
    "\n",
    "def _showVersions():\n",
    "\t# check versions of Python runtime and ML libraries\n",
    "\timport sys\n",
    "\tprint('Python: {}'.format(sys.version))\n",
    "\n",
    "\timport scipy\n",
    "\tprint('scipy: {}'.format(scipy.__version__))\n",
    "\n",
    "\timport numpy\n",
    "\tprint('numpy: {}'.format(numpy.__version__))\n",
    "\n",
    "\timport matplotlib\n",
    "\tprint('matplotlib: {}'.format(matplotlib.__version__))\n",
    "\n",
    "\timport pandas\n",
    "\tprint('pandas: {}'.format(pandas.__version__))\n",
    "\n",
    "\timport sklearn\n",
    "\tprint('sklearn: {}'.format(sklearn.__version__))\n",
    "\t\n",
    "_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
